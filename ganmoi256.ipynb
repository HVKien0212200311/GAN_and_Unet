{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12691770,"sourceType":"datasetVersion","datasetId":8020731},{"sourceId":12693625,"sourceType":"datasetVersion","datasetId":8022041},{"sourceId":512150,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":405396,"modelId":423306},{"sourceId":516623,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":407559,"modelId":425428}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"7970efc1","cell_type":"markdown","source":"# GAN cáº£i tiáº¿n chuyá»ƒn áº£nh grayscale sang RGB\n---\nNotebook chuyá»ƒn tá»« file Python, bao gá»“m quÃ¡ trÃ¬nh xá»­ lÃ½ áº£nh, xÃ¢y dá»±ng Generator/Discriminator, huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡.","metadata":{"id":"7970efc1"}},{"id":"e6c4fff4","cell_type":"code","source":"# CÃ i Ä‘áº·t náº¿u chÆ°a cÃ³ (bá» comment náº¿u cáº§n)\n\n!pip install pytorch-fid lpips\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6c4fff4","executionInfo":{"status":"ok","timestamp":1753725989082,"user_tz":-420,"elapsed":5320,"user":{"displayName":"vukien Hoang","userId":"01038907876462144849"}},"outputId":"5fb62adc-4e1f-4161-d1b0-fe7e3cb988ec","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:17:21.276161Z","iopub.execute_input":"2025-08-11T10:17:21.276423Z","iopub.status.idle":"2025-08-11T10:18:30.582826Z","shell.execute_reply.started":"2025-08-11T10:17:21.276400Z","shell.execute_reply":"2025-08-11T10:18:30.582184Z"}},"outputs":[{"name":"stdout","text":"Collecting pytorch-fid\n  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\nCollecting lpips\n  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (1.26.4)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (11.2.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (1.15.3)\nRequirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from pytorch-fid) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from lpips) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-fid) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.1->pytorch-fid)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.1->pytorch-fid) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.1->pytorch-fid) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.1->pytorch-fid) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pytorch-fid) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pytorch-fid) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pytorch-fid) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pytorch-fid) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pytorch-fid) (2024.2.0)\nDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\nDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-fid, lpips\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed lpips-0.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-fid-0.3.0\n","output_type":"stream"}],"execution_count":1},{"id":"a7c96ce9","cell_type":"code","source":"import shutil\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torchvision.utils import save_image\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom PIL import Image\nimport os\nimport numpy as np\nfrom tqdm import tqdm\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.metrics import structural_similarity as ssim\nfrom pytorch_fid import fid_score\nimport lpips\nimport matplotlib.pyplot as plt\nfrom skimage.color import lab2rgb, rgb2lab # <--- DÃ’NG CODE Cáº¦N THÃŠM HOáº¶C KIá»‚M TRA\n","metadata":{"id":"a7c96ce9","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:18:36.135935Z","iopub.execute_input":"2025-08-11T10:18:36.136538Z","iopub.status.idle":"2025-08-11T10:18:42.692977Z","shell.execute_reply.started":"2025-08-11T10:18:36.136495Z","shell.execute_reply":"2025-08-11T10:18:42.692349Z"}},"outputs":[],"execution_count":2},{"id":"e276b5d4-be0f-47f5-99c2-7b604d8ea509","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6792b7a6-74bf-454e-8747-1748d803b9e7","cell_type":"code","source":"import zipfile\nimport os\n# giáº£i nÃ©n file checkpoint Ä‘Ã£ lÆ°u tá»« local lÃªn \nzip_path = '/kaggle/input/checkpoints1/checkpoints1.zip'\nextract_path = '/kaggle/working/checkpoints1'\n\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall(extract_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e5eda572","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nimage_size = 256\nbatch_size = 16\nlr = 0.0001\nepochs = 100\nSEED_SIZE = 1\n\nINPUT_IMAGE_CHANNELS = 1\nGEN_IMAGE_CHANNELS = 3\n\nsave_dir = '/kaggle/working/output2'\nos.makedirs(save_dir, exist_ok=True)\nsave_bad = '/kaggle/working/bad_images'\nos.makedirs(save_bad, exist_ok=True)\nimg_dir = '/kaggle/input/dataset/data1'\n\n\n\ncheckpoint_dir = '/kaggle/working/checkpoints1'\nos.makedirs(checkpoint_dir, exist_ok=True)\nstart_epoch = 0  # Ä‘á»ƒ khá»Ÿi Ä‘á»™ng láº¡i tá»« epoch cá»¥ thá»ƒ náº¿u resume\nbest_generator_loss = float('inf')\n\n","metadata":{"id":"e5eda572","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753725993626,"user_tz":-420,"elapsed":11,"user":{"displayName":"vukien Hoang","userId":"01038907876462144849"}},"outputId":"9338db69-036a-43dd-b35d-1b1eeffe9123","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:18:49.729289Z","iopub.execute_input":"2025-08-11T10:18:49.729874Z","iopub.status.idle":"2025-08-11T10:18:49.736080Z","shell.execute_reply.started":"2025-08-11T10:18:49.729848Z","shell.execute_reply":"2025-08-11T10:18:49.735309Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"id":"c9da8935-4743-449d-9afc-fd72928d9ec7","cell_type":"code","source":"import shutil  # táº£i láº¡i file checkpoint tá»« local lÃªn input kaggle, roi chuyá»ƒn sang working Ä‘á»ƒ load_checkpoint\ninput_checkpoint_path = \"/kaggle/input/checkpoint11/pytorch/default/1/checkpoint_latest.pth\"\ntarget_checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint_latest.pth\")\nshutil.copy(\"/kaggle/input/checkpoint11/pytorch/default/1/checkpoint_latest.pth\", \"/kaggle/working/checkpoints1/checkpoint_latest.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:19:02.033134Z","iopub.execute_input":"2025-08-11T10:19:02.034126Z","iopub.status.idle":"2025-08-11T10:19:05.767156Z","shell.execute_reply.started":"2025-08-11T10:19:02.034091Z","shell.execute_reply":"2025-08-11T10:19:05.766560Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/checkpoints1/checkpoint_latest.pth'"},"metadata":{}}],"execution_count":5},{"id":"0Umguebtt4Fu","cell_type":"code","source":"\n\ndef save_checkpoint(epoch, generator, discriminator, opt_G, opt_D, best_generator_loss, best_score):\n    checkpoint = {\n        'epoch': epoch,\n        'generator_state_dict': generator.state_dict(),\n        'discriminator_state_dict': discriminator.state_dict(),\n        'opt_G_state_dict': opt_G.state_dict(),\n        'opt_D_state_dict': opt_D.state_dict(),\n        'best_generator_loss': best_generator_loss,\n        'best_score': best_score  # ThÃªm dÃ²ng nÃ y\n    }\n    torch.save(checkpoint, os.path.join(checkpoint_dir, \"checkpoint_latest.pth\"))\n    print(f\"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch {epoch + 1}\")\n\ndef load_checkpoint(generator, discriminator, opt_G, opt_D):\n    \n    path = os.path.join(checkpoint_dir, \"checkpoint_latest.pth\")\n    \n    print(\"ğŸ” Äang kiá»ƒm tra checkpoint:\", path)\n    if os.path.exists(path):\n        checkpoint = torch.load(path, weights_only=False)\n        generator.load_state_dict(checkpoint['generator_state_dict'])\n        discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n        opt_G.load_state_dict(checkpoint['opt_G_state_dict'])\n        opt_D.load_state_dict(checkpoint['opt_D_state_dict'])\n        start_epoch = checkpoint['epoch'] + 1\n        best_generator_loss = checkpoint['best_generator_loss']\n        best_score = checkpoint.get('best_score', -float('inf'))  # ThÃªm dÃ²ng nÃ y\n        print(f\"âœ… ÄÃ£ táº£i checkpoint. Tiáº¿p tá»¥c tá»« epoch {start_epoch}\")\n        return start_epoch, best_generator_loss, best_score\n    else:\n        print(\"âš ï¸ KhÃ´ng tÃ¬m tháº¥y checkpoint. Báº¯t Ä‘áº§u tá»« Ä‘áº§u.\")\n        return 0, float('inf'), -float('inf')  # ThÃªm return máº·c Ä‘á»‹nh","metadata":{"id":"0Umguebtt4Fu","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:19:10.041387Z","iopub.execute_input":"2025-08-11T10:19:10.041654Z","iopub.status.idle":"2025-08-11T10:19:10.048527Z","shell.execute_reply.started":"2025-08-11T10:19:10.041634Z","shell.execute_reply":"2025-08-11T10:19:10.047824Z"}},"outputs":[],"execution_count":6},{"id":"e41e9793","cell_type":"code","source":"valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.gif')\nerror_count = 0\n\nfor root, dirs, files in os.walk(img_dir):\n    for file in files:\n        if file.lower().endswith(valid_extensions):\n            path = os.path.join(root, file)\n            try:\n                with Image.open(path) as img:\n                    img.verify()\n            except Exception as e:\n                error_count += 1\n                print(f\"âŒ áº¢nh lá»—i: {path} ({e})\")\n                shutil.move(path, os.path.join(save_bad, file))\n\nprint(f\"âœ… ÄÃ£ xá»­ lÃ½ xong: {error_count} áº£nh lá»—i Ä‘Ã£ Ä‘Æ°á»£c di chuyá»ƒn vÃ o {save_bad}\")\nclass ColorizationDataset(Dataset):\n    def __init__(self, root_dir, img_size=256, is_train=True):   # 256 thÃ nh 128\n        self.root_dir = root_dir\n        self.img_size = img_size\n        self.is_train = is_train\n        self.image_paths = []\n\n        # Thu tháº­p táº¥t cáº£ cÃ¡c Ä‘Æ°á»ng dáº«n áº£nh trong thÆ° má»¥c gá»‘c vÃ  cÃ¡c thÆ° má»¥c con\n        for root, _, files in os.walk(root_dir):\n            for file in files:\n                if file.lower().endswith(valid_extensions): # Sá»­ dá»¥ng valid_extensions Ä‘Ã£ Ä‘á»‹nh nghÄ©a\n                    self.image_paths.append(os.path.join(root, file))\n\n        # Äá»‹nh nghÄ©a cÃ¡c phÃ©p biáº¿n Ä‘á»•i áº£nh\n        if self.is_train:\n            self.transforms = transforms.Compose([\n                transforms.Resize(self.img_size + 30), # Resize lá»›n hÆ¡n má»™t chÃºt  # chá»‰nh 30 vá» 20 cá»§a 128\n                transforms.RandomCrop(self.img_size),  # Cáº¯t ngáº«u nhiÃªn\n                transforms.RandomHorizontalFlip(),      # Láº­t ngang \n                transforms.RandomRotation(10),          # Xoay ngáº«u nhiÃªn   tá»« 10 vá» 5   cá»§a 128\n                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05), # Cáº£i thiá»‡n ColorJitter\n                transforms.ToTensor(),                  # Chuyá»ƒn Ä‘á»•i sang Tensor (RGB, [0, 1])\n                \n            ])\n        else: # Äá»‘i vá»›i validation/test, chá»‰ cáº§n resize vÃ  chuáº©n hÃ³a\n            self.transforms = transforms.Compose([\n                transforms.Resize((self.img_size, self.img_size)),\n                transforms.ToTensor(),\n               \n            ])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        try:\n            # Má»Ÿ áº£nh vÃ  chuyá»ƒn sang RGB\n            img_rgb_pil = Image.open(img_path).convert('RGB')\n            \n            # Ãp dá»¥ng transforms cho áº£nh RGB (PIL Image)\n            img_rgb_tensor = self.transforms(img_rgb_pil) \n            \n            # Chuyá»ƒn Ä‘á»•i tá»« RGB Tensor vá» numpy array Ä‘á»ƒ sang L*a*b*\n            # skimage.rgb2lab mong Ä‘á»£i numpy array vá»›i giÃ¡ trá»‹ trong khoáº£ng [0, 255]\n            img_rgb_np = img_rgb_tensor.permute(1, 2, 0).numpy() # (C, H, W) -> (H, W, C)\n            #img_rgb_np = (img_rgb_np * 0.5 + 0.5) * 255 # ÄÆ°a vá» khoáº£ng [0, 255] nhÃ¢n hai láº§n 255 khiáº¿n áº£nh sÃ¡ng, lÃ m há»c sai\n             # Chuáº©n hÃ³a Ä‘Ãºng cÃ¡ch tá»« [0, 1] vá» [0, 255] vÃ  Ã©p kiá»ƒu\n            img_rgb_np = (img_rgb_np * 255).astype(np.uint8) # <-- DÃ²ng Ä‘Ã£ sá»­a\n            \n            # Chuyá»ƒn Ä‘á»•i sang khÃ´ng gian mÃ u L*a*b*\n            img_lab = rgb2lab(img_rgb_np).astype(\"float32\") \n            \n            # TÃ¡ch kÃªnh L vÃ  kÃªnh a, b, sau Ä‘Ã³ chuáº©n hÃ³a vá» [-1, 1]\n            L = img_lab[:, :, 0] / 50.0 - 1.0 # KÃªnh L: [0, 100] -> [-1, 1]\n            ab = img_lab[:, :, 1:] / 128.0   # KÃªnh a, b: [-128, 128] -> [-1, 1]\n            \n            # Chuyá»ƒn numpy array vá» Tensor vÃ  Ä‘á»‹nh dáº¡ng Ä‘Ãºng (C, H, W)\n            L = torch.from_numpy(L).unsqueeze(0) # (1, H, W)\n            ab = torch.from_numpy(ab).permute(2, 0, 1) # (2, H, W)\n\n            return L, ab # Tráº£ vá» kÃªnh L (grayscale) vÃ  kÃªnh ab (color)\n\n        except Exception as e:\n            print(f\"âŒ Bá» qua áº£nh lá»—i khi load (táº¡i getitem): {img_path} ({e}). Tráº£ vá» dummy tensors.\")\n            # Tráº£ vá» dummy tensors vá»›i kÃ­ch thÆ°á»›c chÃ­nh xÃ¡c cho IMG_SIZE\n            dummy_L = torch.zeros((1, self.img_size, self.img_size))\n            dummy_ab = torch.zeros((2, self.img_size, self.img_size))\n            return dummy_L, dummy_ab\n\n\n\ndataset = ColorizationDataset(\n    root_dir=img_dir,\n    img_size=image_size,\n    is_train=True # is_train chá»‰ áº£nh hÆ°á»Ÿng Ä‘áº¿n augmentations, khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n viá»‡c chia dataset\n)\ntrain_dataset, test_dataset = random_split(dataset, [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))])\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nprint(\"Train size:\", len(train_dataset), \"Test size:\", len(test_dataset)) ","metadata":{"id":"e41e9793","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753726017520,"user_tz":-420,"elapsed":20084,"user":{"displayName":"vukien Hoang","userId":"01038907876462144849"}},"outputId":"e73d8072-3477-422c-8c52-efcf470d983c","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:19:13.107363Z","iopub.execute_input":"2025-08-11T10:19:13.107930Z","iopub.status.idle":"2025-08-11T10:19:34.090633Z","shell.execute_reply.started":"2025-08-11T10:19:13.107904Z","shell.execute_reply":"2025-08-11T10:19:34.089924Z"}},"outputs":[{"name":"stdout","text":"âœ… ÄÃ£ xá»­ lÃ½ xong: 0 áº£nh lá»—i Ä‘Ã£ Ä‘Æ°á»£c di chuyá»ƒn vÃ o /kaggle/working/bad_images\nTrain size: 1835 Test size: 459\n","output_type":"stream"}],"execution_count":7},{"id":"6dd56e1b-d41e-4d57-924e-be400ffdfb37","cell_type":"code","source":"sample_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\nfor L, ab in sample_loader:\n    print(\"L shape:\", L.shape)\n    print(\"ab shape:\", ab.shape)\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:19:41.322160Z","iopub.execute_input":"2025-08-11T10:19:41.322433Z","iopub.status.idle":"2025-08-11T10:19:42.392902Z","shell.execute_reply.started":"2025-08-11T10:19:41.322410Z","shell.execute_reply":"2025-08-11T10:19:42.391916Z"}},"outputs":[{"name":"stdout","text":"L shape: torch.Size([16, 1, 256, 256])\nab shape: torch.Size([16, 2, 256, 256])\n","output_type":"stream"}],"execution_count":8},{"id":"df63aa11-19d9-444e-baf8-6d723d2d4078","cell_type":"code","source":"# ----------- Self-Attention Block (ÄÃ£ sá»­a Ä‘á»•i) -----------\nclass SelfAttention(nn.Module):\n    \"\"\"\n    Block Self-Attention (ÄÃ£ sá»­a lá»—i CUDA assert).\n    Máº·c dÃ¹ phiÃªn báº£n cÅ© khÃ´ng sai vá» logic, nhÆ°ng Ä‘Ã´i khi\n    cÃ¡ch sáº¯p xáº¿p tensor cÃ³ thá»ƒ gÃ¢y ra lá»—i khÃ´ng mong muá»‘n trÃªn GPU.\n    PhiÃªn báº£n nÃ y sá»­ dá»¥ng má»™t cÃ¡ch viáº¿t phá»• biáº¿n vÃ  á»•n Ä‘á»‹nh hÆ¡n.\n    \"\"\"\n    def __init__(self, in_dim):\n        super(SelfAttention, self).__init__()\n        self.query = nn.Conv2d(in_dim, max(in_dim // 8, 1), 1)\n        self.key = nn.Conv2d(in_dim, max(in_dim // 8, 1), 1)\n        self.value = nn.Conv2d(in_dim, in_dim, 1)\n        self.gamma = nn.Parameter(torch.zeros(1))\n\n    def forward(self, x):\n        B, C, H, W = x.size()\n        # Chuyá»ƒn Ä‘á»•i tensor Ä‘á»ƒ tÃ­nh toÃ¡n\n        proj_query = self.query(x).reshape(B, -1, H * W)  # B x (C/8) x N\n        proj_key = self.key(x).reshape(B, -1, H * W)      # B x (C/8) x N\n        proj_value = self.value(x).reshape(B, -1, H * W)  # B x C x N\n\n        # TÃ­nh attention map\n        # (B x N x C/8) x (B x C/8 x N) -> (B x N x N)\n        attention = torch.bmm(proj_key.permute(0, 2, 1), proj_query)\n        attention = F.softmax(attention, dim=-1)\n\n        # Ãp dá»¥ng attention map lÃªn value\n        # (B x C x N) x (B x N x N) -> (B x C x N)\n        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n        \n        # Reshape láº¡i vá» kÃ­ch thÆ°á»›c ban Ä‘áº§u\n        out = out.view(B, C, H, W)\n\n        # ThÃªm káº¿t quáº£ vÃ o Ä‘áº§u vÃ o ban Ä‘áº§u\n        return self.gamma * out + x\n\n# ----------- Residual Block -----------\nclass ResidualBlock(nn.Module):\n    \"\"\"\n    Block dÆ° cÆ¡ báº£n Ä‘á»ƒ thÃªm vÃ o giá»¯a cÃ¡c lá»›p.\n    \"\"\"\n    def __init__(self, in_channels):\n        super(ResidualBlock, self).__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(in_channels, in_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(in_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(in_channels, in_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(in_channels)\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\n# ----------- SE Block (Channel Attention) -----------\nclass SEBlock(nn.Module):\n    \"\"\"\n    Squeeze-and-Excitation Block Ä‘á»ƒ táº¡o attention theo kÃªnh.\n    \"\"\"\n    def __init__(self, in_channels, reduction=16):\n        super(SEBlock, self).__init__()\n        self.fc = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(in_channels, max(in_channels // reduction, 1), 1),\n            nn.ReLU(),\n            nn.Conv2d(max(in_channels // reduction, 1), in_channels, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        w = self.fc(x)\n        return x * w\n\n# ----------- Downsampling Block -----------\ndef down_block(in_channels, out_channels, use_attn=False):\n    \"\"\"\n    HÃ m táº¡o Downsampling Block vá»›i cÃ¡c lá»›p tiÃªu chuáº©n vÃ  SEBlock.\n    \"\"\"\n    layers = [\n        nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(out_channels),\n        nn.LeakyReLU(0.2, inplace=True),\n        SEBlock(out_channels)\n    ]\n    if use_attn:\n        layers.append(SelfAttention(out_channels))\n    return nn.Sequential(*layers)\n\n# ----------- Upsampling Block -----------\ndef up_block(in_channels, out_channels, dropout=False, use_attn=False):\n    \"\"\"\n    HÃ m táº¡o Upsampling Block vá»›i cÃ¡c lá»›p tiÃªu chuáº©n vÃ  SEBlock.\n    \"\"\"\n    layers = [\n        nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(inplace=True),\n        SEBlock(out_channels)\n    ]\n    if dropout:\n        layers.append(nn.Dropout(0.5))\n    if use_attn:\n        layers.append(SelfAttention(out_channels))\n    return nn.Sequential(*layers)\n\n# ----------- Generator Main Model -----------\nclass UNetGenerator(nn.Module):\n    \"\"\"\n    MÃ´ hÃ¬nh Generator dáº¡ng U-Net cáº£i tiáº¿n Ä‘á»ƒ chuyá»ƒn áº£nh xÃ¡m sang mÃ u.\n    Äáº§u vÃ o: 1 kÃªnh (L*)\n    Äáº§u ra: 2 kÃªnh (a* vÃ  b*)\n    \"\"\"\n    def __init__(self, input_channels=1, output_channels=2):\n        super(UNetGenerator, self).__init__()\n        # Downsampling\n        self.d1 = down_block(input_channels, 64)\n        self.d2 = down_block(64, 128)\n        self.d3 = down_block(128, 256)\n        self.d4 = down_block(256, 512)\n\n        # Middle\n        self.middle = nn.Sequential(\n            ResidualBlock(512),\n            SelfAttention(512),\n            ResidualBlock(512)\n        )\n\n        # Upsampling\n        self.u1 = up_block(512 * 2, 256, dropout=True)\n        self.u2 = up_block(256 * 2, 128, use_attn=True)\n        self.u3 = up_block(128 * 2, 64)\n        self.u4 = up_block(64 * 2, 32)\n\n        # Final conv + thÃªm 1 residual block trÆ°á»›c Tanh\n        self.final = nn.Sequential(\n            ResidualBlock(32),\n            nn.Conv2d(32, output_channels, 3, 1, 1, bias=True),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        d1 = self.d1(x)\n        d2 = self.d2(d1)\n        d3 = self.d3(d2)\n        d4 = self.d4(d3)\n\n        m = self.middle(d4)\n\n        u1 = self.u1(torch.cat([m, d4], dim=1))\n        u2 = self.u2(torch.cat([u1, d3], dim=1))\n        u3 = self.u3(torch.cat([u2, d2], dim=1))\n        u4 = self.u4(torch.cat([u3, d1], dim=1))\n\n        out = self.final(u4)\n\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:20:07.201726Z","iopub.execute_input":"2025-08-11T10:20:07.201970Z","iopub.status.idle":"2025-08-11T10:20:07.218272Z","shell.execute_reply.started":"2025-08-11T10:20:07.201954Z","shell.execute_reply":"2025-08-11T10:20:07.217467Z"}},"outputs":[],"execution_count":9},{"id":"50195833-6fa7-455b-ac79-149a8a18b4b0","cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, in_channels=3):\n        super(Discriminator, self).__init__()\n\n        def conv_block(in_c, out_c, normalize=True):\n            layers = [nn.Conv2d(in_c, out_c, 4, 2, 1, bias=False)]\n            if normalize:\n                layers.append(nn.BatchNorm2d(out_c))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return nn.Sequential(*layers)\n\n        self.block1 = conv_block(in_channels, 64, normalize=False)\n        self.block2 = conv_block(64, 128)\n        self.block3 = conv_block(128, 256)\n        self.block4 = conv_block(256, 512)\n        \n        self.res = ResidualBlock(512)\n        # Sá»­ dá»¥ng SelfAttention Ä‘Ã£ sá»­a lá»—i á»Ÿ trÃªn\n        self.attn = SelfAttention(512)\n        \n        self.output_layer = nn.Sequential(\n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0,bias=True),\n        )\n\n    def forward(self, x):\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.res(x)\n        x = self.attn(x)\n        x = self.output_layer(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:20:10.849703Z","iopub.execute_input":"2025-08-11T10:20:10.849974Z","iopub.status.idle":"2025-08-11T10:20:10.856593Z","shell.execute_reply.started":"2025-08-11T10:20:10.849954Z","shell.execute_reply":"2025-08-11T10:20:10.855776Z"}},"outputs":[],"execution_count":10},{"id":"ea32eaf5-5c22-4ea1-9d2c-f007e6f1acbf","cell_type":"code","source":"import warnings\n# TÃ¹y chá»n: áº©n cáº£nh bÃ¡o \"negative Z values\" tá»« skimage\nwarnings.filterwarnings(\"ignore\", message=\"Conversion from CIE-LAB.*\", category=UserWarning)\n\nimport numpy as np\nimport torch\nfrom skimage.color import lab2rgb\n\ndef lab_to_rgb_tensor(L_channel, ab_channel):\n    \"\"\"\n    Chuyá»ƒn Ä‘á»•i tá»« tensor LAB sang tensor RGB.\n    \n    Args:\n        L_channel (torch.Tensor): KÃªnh L (lightness), giÃ¡ trá»‹ trong khoáº£ng [-1, 1]. Shape: (B, 1, H, W)\n        ab_channel (torch.Tensor): KÃªnh a vÃ  b, giÃ¡ trá»‹ trong khoáº£ng [-1, 1]. Shape: (B, 2, H, W)\n        device: 'cuda' hoáº·c 'cpu'\n\n    Returns:\n        torch.Tensor: Tensor RGB, giÃ¡ trá»‹ trong khoáº£ng [-1, 1]. Shape: (B, 3, H, W)\n    \"\"\"\n    device = L_channel.device  # Láº¥y device tá»« input\n    # 1. Chuyá»ƒn Ä‘á»•i tensor vá» numpy\n    L_np = L_channel.detach().cpu().numpy()\n    ab_np = ab_channel.detach().cpu().numpy()\n    \n    # 2. Chuáº©n hÃ³a ngÆ°á»£c vá» cÃ¡c giÃ¡ trá»‹ LAB gá»‘c\n    # L trong khÃ´ng gian LAB chuáº©n cÃ³ giÃ¡ trá»‹ tá»« [0, 100]\n    # a, b trong khÃ´ng gian LAB chuáº©n cÃ³ giÃ¡ trá»‹ tá»« [-128, 128]\n    L_np = (L_np + 1.0) / 2.0 * 100.0  # Chuáº©n hÃ³a ngÆ°á»£c kÃªnh L tá»« [-1, 1] vá» [0, 100]\n    ab_np = ab_np * 128.0 # Chuáº©n hÃ³a ngÆ°á»£c kÃªnh ab tá»« [-1, 1] vá» [-128, 128]\n    \n    # 3. Káº¿t há»£p cÃ¡c kÃªnh\n    lab_np = np.concatenate((L_np, ab_np), axis=1) # (B, 3, H, W)\n    lab_np = lab_np.transpose((0, 2, 3, 1)) # (B, H, W, 3)\n\n    rgb_imgs = []\n    for img_lab in lab_np:\n        # img_lab cÃ³ shape (H, W, 3)\n        img_rgb = lab2rgb(img_lab)  # tráº£ vá» áº£nh RGB cÃ³ dáº£i giÃ¡ trá»‹ [0, 1]\n        rgb_imgs.append(img_rgb)\n    \n    # 4. Chuyá»ƒn láº¡i vá» tensor vÃ  chuáº©n hÃ³a\n    rgb_imgs = np.stack(rgb_imgs, axis=0) # (B, H, W, 3)\n    rgb_imgs = torch.from_numpy(rgb_imgs).permute(0, 3, 1, 2) # (B, 3, H, W)\n    \n    # Chuáº©n hÃ³a RGB tá»« [0, 1] vá» [-1, 1] Ä‘á»ƒ phÃ¹ há»£p vá»›i mÃ´ hÃ¬nh\n    rgb_imgs = rgb_imgs * 2.0 - 1.0\n\n    return rgb_imgs.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:20:13.451156Z","iopub.execute_input":"2025-08-11T10:20:13.451414Z","iopub.status.idle":"2025-08-11T10:20:13.457939Z","shell.execute_reply.started":"2025-08-11T10:20:13.451394Z","shell.execute_reply":"2025-08-11T10:20:13.457182Z"}},"outputs":[],"execution_count":11},{"id":"556d8a2f-c132-440e-9d0e-0940e4133954","cell_type":"code","source":"import os\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a81f7556-77b6-4d26-9235-de85f8ffc4d5","cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"wYlY6ttFLfg6","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport lpips\nimport json\nimport cv2\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom skimage.metrics import peak_signal_noise_ratio as psnr_fn\nfrom skimage.metrics import structural_similarity as ssim_fn\nfrom pytorch_fid import fid_score\nfrom tqdm import tqdm\nimport os\nimport zipfile\nimport tempfile\nfrom torchvision import transforms\nimport numpy as np\n\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\nimport warnings\nwarnings.filterwarnings(\"ignore\", message=\"Conversion from CIE-LAB.*\", category=UserWarning)\n\ndef zip_folder(folder_path, zip_path):\n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for root, _, files in os.walk(folder_path):\n            for file in files:\n                filepath = os.path.join(root, file)\n                arcname = os.path.relpath(filepath, folder_path)\n                zipf.write(filepath, arcname)\n\ndef tensor_to_numpy(img):\n    img = img.detach().cpu().clamp(0, 1)\n    return img.permute(1, 2, 0).numpy()\n\n# Giáº£ Ä‘á»‹nh cÃ¡c hÃ m sau Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a:\n# - UNetGenerator: MÃ´ hÃ¬nh Generator vá»›i input_channels=1, output_channels=2\n# - Discriminator: MÃ´ hÃ¬nh Discriminator vá»›i in_channels=3\n# - lab_to_rgb_tensor: HÃ m chuyá»ƒn Ä‘á»•i tá»« L*a*b* sang RGB\n# - save_image: HÃ m lÆ°u áº£nh tá»« tensor\n# - save_checkpoint, load_checkpoint: HÃ m lÆ°u/táº£i checkpoint\n# - train_loader, test_loader: DataLoader cho dá»¯ liá»‡u huáº¥n luyá»‡n/kiá»ƒm tra\n# - save_dir, checkpoint_dir: ThÆ° má»¥c lÆ°u káº¿t quáº£/checkpoint\n# - device: Thiáº¿t bá»‹ (CPU/GPU)\n\n# Khá»Ÿi táº¡o mÃ´ hÃ¬nh\nbest_generator_weights = None\ngenerator = UNetGenerator(input_channels=1, output_channels=2).to(device)\ndiscriminator = Discriminator(in_channels=3).to(device)\nlpips_loss_fn = lpips.LPIPS(net='alex').to(device)\nl1_loss_fn = nn.L1Loss()\nbce_loss_fn = nn.BCEWithLogitsLoss()\n\n# Tá»‘i Æ°u hÃ³a\nopt_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\nopt_D = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n\nbest_score = -float('inf')\nresume_training = True\n\nif resume_training:\n    start_epoch, best_generator_loss, best_score = load_checkpoint(generator, discriminator, opt_G, opt_D)\nelse:\n    print(\"ğŸš€ Äang khá»Ÿi Ä‘á»™ng training tá»« Ä‘áº§u...\")\n    start_epoch = 0\n    best_generator_loss = float('inf')\n\n# Ghi log ra file\nlog_file_path = os.path.join(save_dir, \"training_log.txt\")\nlog_file = open(log_file_path, \"a\" if resume_training else \"w\")\nG_losses, D_losses = [], []\nPSNR_scores, SSIM_scores, LPIPS_scores, FID_scores = [], [], [], []\nbest_epoch = -1\n\n# Trá»ng sá»‘ loss\nLAMBDA_L1 = 200\nLAMBDA_LPIPS = 20\nLAMBDA_ADV = 1  # TÄƒng Ä‘á»ƒ áº£nh tá»± nhiÃªn hÆ¡n\n\ntest_L, test_ab_fake = None, None\nepochs = 100 - start_epoch\n\nfor epoch in range(start_epoch, start_epoch + epochs):\n    g_loss_epoch, d_loss_epoch = 0, 0\n    psnr_total, ssim_total, lpips_total = 0, 0, 0\n    n_samples = 0\n    loop = tqdm(train_loader, desc=f\"Epoch [{epoch + 1}/{epochs}]\")\n\n    for L_channel_real, ab_channel_real in loop:\n        L_channel_real, ab_channel_real = L_channel_real.to(device), ab_channel_real.to(device)\n        \n        # Kiá»ƒm tra Ä‘á»‹nh dáº¡ng tensor\n        assert L_channel_real.size(1) == 1, f\"Expected 1 channel for L, got {L_channel_real.size(1)}\"\n        assert ab_channel_real.size(1) == 2, f\"Expected 2 channels for ab, got {ab_channel_real.size(1)}\"\n\n        # TRAIN DISCRIMINATOR\n        opt_D.zero_grad()\n        real_img_for_D = torch.cat([L_channel_real, ab_channel_real], dim=1)\n        d_real = discriminator(real_img_for_D)\n        d_loss_real = bce_loss_fn(d_real, torch.ones_like(d_real) * 0.9)\n        \n        fake_ab_channel = generator(L_channel_real).detach()\n        fake_img_for_D = torch.cat([L_channel_real, fake_ab_channel], dim=1)\n        d_fake = discriminator(fake_img_for_D)\n        d_loss_fake = bce_loss_fn(d_fake, torch.zeros_like(d_fake) * 0.1)\n        \n        d_loss = (d_loss_real + d_loss_fake) / 2\n        d_loss.backward()\n        opt_D.step()\n\n        # TRAIN GENERATOR\n        opt_G.zero_grad()\n        fake_ab_channel = generator(L_channel_real)\n        fake_img_for_D_G = torch.cat([L_channel_real, fake_ab_channel], dim=1)\n        d_fake_for_G = discriminator(fake_img_for_D_G)\n        adv_loss = bce_loss_fn(d_fake_for_G, torch.ones_like(d_fake_for_G) * 0.9)\n        \n        reconstruction_loss = l1_loss_fn(fake_ab_channel, ab_channel_real)\n        \n        real_rgb_for_lpips = lab_to_rgb_tensor(L_channel_real, ab_channel_real).float()\n        fake_rgb_for_lpips = lab_to_rgb_tensor(L_channel_real, fake_ab_channel).float()\n        perceptual_loss = lpips_loss_fn(fake_rgb_for_lpips, real_rgb_for_lpips).mean()\n        \n        g_loss = LAMBDA_ADV * adv_loss + LAMBDA_L1 * reconstruction_loss + LAMBDA_LPIPS * perceptual_loss \n        g_loss.backward()\n        opt_G.step()\n\n        # TÃ­nh chá»‰ sá»‘ hÃ¬nh áº£nh\n        for i in range(real_rgb_for_lpips.size(0)):\n            gt_rgb = lab_to_rgb_tensor(L_channel_real[i:i+1], ab_channel_real[i:i+1]).squeeze(0)\n            pred_rgb = lab_to_rgb_tensor(L_channel_real[i:i+1], fake_ab_channel[i:i+1]).squeeze(0)\n            gt_np = (gt_rgb.detach().cpu().permute(1, 2, 0).numpy() + 1) / 2\n            pred_np = (pred_rgb.detach().cpu().permute(1, 2, 0).numpy() + 1) / 2\n            \n            psnr_total += psnr_fn(gt_np, pred_np, data_range=1)\n            ssim_total += ssim_fn(gt_np, pred_np, data_range=1, channel_axis=-1)\n        \n        lpips_total += perceptual_loss.item() * real_rgb_for_lpips.size(0)\n        n_samples += real_rgb_for_lpips.size(0)\n\n        loop.set_postfix(G_Loss=g_loss.item(), D_Loss=d_loss.item())\n        g_loss_epoch += g_loss.item()\n        d_loss_epoch += d_loss.item()\n\n    # TÃ­nh FID\n    \n    temp_real_dir = tempfile.mkdtemp()\n    temp_gen_dir = tempfile.mkdtemp()\n\n    test_L = L_channel_real[:128].detach()\n    test_ab_fake = fake_ab_channel[:128].detach()\n\n    for i in range(test_L.size(0)):\n        real_rgb = lab_to_rgb_tensor(test_L[i:i+1], ab_channel_real[i:i+1]).squeeze(0)\n        fake_rgb = lab_to_rgb_tensor(test_L[i:i+1], test_ab_fake[i:i+1]).squeeze(0)\n    \n        real_rgb = (real_rgb + 1) / 2\n        fake_rgb = (fake_rgb + 1) / 2\n    \n        transforms.ToPILImage()(real_rgb).save(f\"{temp_real_dir}/{i}.png\")\n        transforms.ToPILImage()(fake_rgb).save(f\"{temp_gen_dir}/{i}.png\")\n    \n    fid = fid_score.calculate_fid_given_paths(\n        [temp_real_dir, temp_gen_dir],\n        batch_size=16,\n        device=device,\n        dims=2048\n    )\n\n\n\n\n    # Cáº­p nháº­t metrics\n    G_avg = g_loss_epoch / len(train_loader)\n    D_avg = d_loss_epoch / len(train_loader)\n    psnr_avg = psnr_total / n_samples\n    ssim_avg = ssim_total / n_samples\n    lpips_avg = lpips_total / n_samples\n    FID_scores.append(fid)\n\n    G_losses.append(G_avg)\n    D_losses.append(D_avg)\n    PSNR_scores.append(psnr_avg)\n    SSIM_scores.append(ssim_avg)\n    LPIPS_scores.append(lpips_avg)\n\n    # Ghi metrics ra file JSON\n    metrics = {\n        'G_losses': G_losses,\n        'D_losses': D_losses,\n        'PSNR_scores': PSNR_scores,\n        'SSIM_scores': SSIM_scores,\n        'LPIPS_scores': LPIPS_scores,\n        'FID_scores': FID_scores\n    }\n    with open(os.path.join(save_dir, 'metrics.json'), 'w') as f:\n        json.dump(metrics, f)\n\n    # Ghi log\n    log_file.write(\n        f\"Epoch {epoch + 1:03d}:\\n\"\n        f\"  G_Loss:  {G_avg:.4f}\\n\"\n        f\"  D_Loss:  {D_avg:.4f}\\n\"\n        f\"  PSNR:    {psnr_avg:.2f}\\n\"\n        f\"  SSIM:    {ssim_avg:.4f}\\n\"\n        f\"  LPIPS:   {lpips_avg:.4f}\\n\"\n        f\"  FID:     {fid:.4f}\\n\"\n        \"-------------------------\\n\"\n    )\n    log_file.flush()\n\n    # LÆ°u áº£nh káº¿t quáº£\n    fake_rgb_to_save = lab_to_rgb_tensor(test_L, test_ab_fake)\n    ##print(\"Fake RGB tensor stats:\", fake_rgb_to_save.min().item(), fake_rgb_to_save.max().item())\n    # Chuyá»ƒn tá»« [-1, 1] vá» [0, 1]  Ä‘á»ƒ hiá»ƒn thá»‹ áº£nh vÃ¬ hÃ m lab_to_rgb_tensor Ä‘ang á»Ÿ dáº£i [-1, 1]\n    fake_rgb_to_save = (fake_rgb_to_save + 1.0) / 2.0 \n    save_image(\n    (fake_rgb_to_save[:30]),\n    os.path.join(save_dir, f\"epoch_{epoch + 1}.png\"),\n    nrow=5,\n    normalize=False  # hoáº·c bá» normalize luÃ´n\n)\n\n\n    # LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t\n    score = -10 * lpips_avg + 5.0 * ssim_avg +  psnr_avg # kh cáº§n fid láº¯m vÃ¬ Æ°u tiÃªn 3 cÃ¡i kia hÆ¡n - 0.02 * fid\n    \n    \n\n    if score > best_score:\n        best_score = score\n        best_generator_weights = generator.state_dict()\n        best_epoch = epoch + 1\n        torch.save(best_generator_weights, os.path.join(save_dir, 'generator_best.pth'))\n        print(f\"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch {best_epoch} vá»›i PSNR = {psnr_avg:.4f}, LPIPS = {lpips_avg:.4f}, SSIM = {ssim_avg:.4f}, FID = {fid:.4f}, Score = {best_score:.4f}\")\n   \n    save_checkpoint(epoch, generator, discriminator, opt_G, opt_D, best_generator_loss, best_score)\n\n    if (epoch + 1) % 10 == 0:\n        print(f\"ğŸ—œï¸ Äang nÃ©n output táº¡i epoch {epoch + 1}...\")\n        zip_folder(save_dir, f'/kaggle/working/output_epoch{epoch + 1}.zip')\n\n    if (epoch + 1) % 20 == 0:\n        print(f\"ğŸ—œï¸ Äang nÃ©n checkpoint táº¡i epoch {epoch + 1}...\")\n        zip_folder(checkpoint_dir, f'/kaggle/working/checkpoints_epoch{epoch + 1}.zip')\n    \n# LÆ°u mÃ´ hÃ¬nh cuá»‘i cÃ¹ng\ntorch.save(generator.state_dict(), os.path.join(save_dir, 'generator_final.pth'))\ntorch.save(discriminator.state_dict(), os.path.join(save_dir, 'discriminator_final.pth'))\n\nlog_file.close()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"wYlY6ttFLfg6","executionInfo":{"status":"error","timestamp":1753726910422,"user_tz":-420,"elapsed":19337,"user":{"displayName":"vukien Hoang","userId":"01038907876462144849"}},"outputId":"ff6182cb-2cb2-4f85-c413-2dc4819b6179","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T10:20:21.788814Z","iopub.execute_input":"2025-08-11T10:20:21.789079Z","iopub.status.idle":"2025-08-11T13:46:09.645965Z","shell.execute_reply.started":"2025-08-11T10:20:21.789059Z","shell.execute_reply":"2025-08-11T13:46:09.645189Z"}},"outputs":[{"name":"stdout","text":"Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233M/233M [00:01<00:00, 206MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\nğŸ” Äang kiá»ƒm tra checkpoint: /kaggle/working/checkpoints1/checkpoint_latest.pth\nâœ… ÄÃ£ táº£i checkpoint. Tiáº¿p tá»¥c tá»« epoch 52\n","output_type":"stream"},{"name":"stderr","text":"Epoch [53/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:09<00:00,  2.17s/it, D_Loss=0.486, G_Loss=20]  \nDownloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91.2M/91.2M [00:00<00:00, 266MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 53\n","output_type":"stream"},{"name":"stderr","text":"Epoch [54/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.16s/it, D_Loss=0.322, G_Loss=21.2]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 54\n","output_type":"stream"},{"name":"stderr","text":"Epoch [55/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.516, G_Loss=26.3]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 55\n","output_type":"stream"},{"name":"stderr","text":"Epoch [56/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.253, G_Loss=24.1]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 56\n","output_type":"stream"},{"name":"stderr","text":"Epoch [57/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:05<00:00,  2.13s/it, D_Loss=0.411, G_Loss=22]  \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 57\n","output_type":"stream"},{"name":"stderr","text":"Epoch [58/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.15s/it, D_Loss=0.667, G_Loss=22.5]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 58\n","output_type":"stream"},{"name":"stderr","text":"Epoch [59/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:08<00:00,  2.16s/it, D_Loss=0.696, G_Loss=24.1]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 59 vá»›i PSNR = 22.0929, LPIPS = 0.2174, SSIM = 0.8864, FID = 152.3779, Score = 24.3512\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 59\n","output_type":"stream"},{"name":"stderr","text":"Epoch [60/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:05<00:00,  2.13s/it, D_Loss=0.364, G_Loss=26.4]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 60\nğŸ—œï¸ Äang nÃ©n output táº¡i epoch 60...\nğŸ—œï¸ Äang nÃ©n checkpoint táº¡i epoch 60...\n","output_type":"stream"},{"name":"stderr","text":"Epoch [61/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:05<00:00,  2.13s/it, D_Loss=0.338, G_Loss=26]  \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 61\n","output_type":"stream"},{"name":"stderr","text":"Epoch [62/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:05<00:00,  2.13s/it, D_Loss=0.405, G_Loss=21.3]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 62\n","output_type":"stream"},{"name":"stderr","text":"Epoch [63/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=1.11, G_Loss=20.4] \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 63\n","output_type":"stream"},{"name":"stderr","text":"Epoch [64/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.15s/it, D_Loss=0.554, G_Loss=24.7]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 64\n","output_type":"stream"},{"name":"stderr","text":"Epoch [65/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.14s/it, D_Loss=0.349, G_Loss=26.5]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 65\n","output_type":"stream"},{"name":"stderr","text":"Epoch [66/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.14s/it, D_Loss=0.701, G_Loss=23.5]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 66 vá»›i PSNR = 22.1517, LPIPS = 0.2174, SSIM = 0.8889, FID = 173.7209, Score = 24.4221\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 66\n","output_type":"stream"},{"name":"stderr","text":"Epoch [67/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:09<00:00,  2.17s/it, D_Loss=0.903, G_Loss=17.5]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 67 vá»›i PSNR = 22.1802, LPIPS = 0.2156, SSIM = 0.8916, FID = 126.1514, Score = 24.4820\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 67\n","output_type":"stream"},{"name":"stderr","text":"Epoch [68/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:08<00:00,  2.16s/it, D_Loss=0.383, G_Loss=21]  \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 68\n","output_type":"stream"},{"name":"stderr","text":"Epoch [69/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.374, G_Loss=25.5]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 69 vá»›i PSNR = 22.1938, LPIPS = 0.2140, SSIM = 0.8921, FID = 133.8705, Score = 24.5141\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 69\n","output_type":"stream"},{"name":"stderr","text":"Epoch [70/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:08<00:00,  2.16s/it, D_Loss=0.303, G_Loss=26]  \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 70\nğŸ—œï¸ Äang nÃ©n output táº¡i epoch 70...\n","output_type":"stream"},{"name":"stderr","text":"Epoch [71/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.297, G_Loss=22.7]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 71\n","output_type":"stream"},{"name":"stderr","text":"Epoch [72/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:08<00:00,  2.16s/it, D_Loss=0.366, G_Loss=24.3]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 72\n","output_type":"stream"},{"name":"stderr","text":"Epoch [73/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.634, G_Loss=21.1]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 73\n","output_type":"stream"},{"name":"stderr","text":"Epoch [74/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.14s/it, D_Loss=0.769, G_Loss=21]  \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 74\n","output_type":"stream"},{"name":"stderr","text":"Epoch [75/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:05<00:00,  2.14s/it, D_Loss=0.241, G_Loss=24]  \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 75 vá»›i PSNR = 22.1953, LPIPS = 0.2139, SSIM = 0.8927, FID = 165.4128, Score = 24.5195\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 75\n","output_type":"stream"},{"name":"stderr","text":"Epoch [76/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.14s/it, D_Loss=0.396, G_Loss=19.3]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 76 vá»›i PSNR = 22.2679, LPIPS = 0.2149, SSIM = 0.8908, FID = 158.2311, Score = 24.5725\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 76\n","output_type":"stream"},{"name":"stderr","text":"Epoch [77/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:05<00:00,  2.14s/it, D_Loss=0.616, G_Loss=29]  \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 77\n","output_type":"stream"},{"name":"stderr","text":"Epoch [78/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.15s/it, D_Loss=0.224, G_Loss=24.9]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 78\n","output_type":"stream"},{"name":"stderr","text":"Epoch [79/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.16s/it, D_Loss=0.736, G_Loss=22.7]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 79\n","output_type":"stream"},{"name":"stderr","text":"Epoch [80/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:05<00:00,  2.14s/it, D_Loss=0.819, G_Loss=17.4]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 80\nğŸ—œï¸ Äang nÃ©n output táº¡i epoch 80...\nğŸ—œï¸ Äang nÃ©n checkpoint táº¡i epoch 80...\n","output_type":"stream"},{"name":"stderr","text":"Epoch [81/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.15s/it, D_Loss=0.338, G_Loss=26.2]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 81\n","output_type":"stream"},{"name":"stderr","text":"Epoch [82/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:08<00:00,  2.16s/it, D_Loss=0.312, G_Loss=24.1]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 82\n","output_type":"stream"},{"name":"stderr","text":"Epoch [83/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.463, G_Loss=19.4]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 83\n","output_type":"stream"},{"name":"stderr","text":"Epoch [84/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.421, G_Loss=24.5]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 84 vá»›i PSNR = 22.3027, LPIPS = 0.2111, SSIM = 0.8911, FID = 155.0772, Score = 24.6467\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 84\n","output_type":"stream"},{"name":"stderr","text":"Epoch [85/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.14s/it, D_Loss=0.259, G_Loss=22.4]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 85\n","output_type":"stream"},{"name":"stderr","text":"Epoch [86/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.294, G_Loss=26.9]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 86 vá»›i PSNR = 22.3440, LPIPS = 0.2119, SSIM = 0.8942, FID = 141.3041, Score = 24.6957\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 86\n","output_type":"stream"},{"name":"stderr","text":"Epoch [87/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.14s/it, D_Loss=0.513, G_Loss=18.6]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 87\n","output_type":"stream"},{"name":"stderr","text":"Epoch [88/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:09<00:00,  2.17s/it, D_Loss=0.387, G_Loss=27.6]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 88\n","output_type":"stream"},{"name":"stderr","text":"Epoch [89/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:09<00:00,  2.17s/it, D_Loss=0.965, G_Loss=17.8]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 89\n","output_type":"stream"},{"name":"stderr","text":"Epoch [90/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:09<00:00,  2.17s/it, D_Loss=0.377, G_Loss=23]  \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 90\nğŸ—œï¸ Äang nÃ©n output táº¡i epoch 90...\n","output_type":"stream"},{"name":"stderr","text":"Epoch [91/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.807, G_Loss=19.4]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 91\n","output_type":"stream"},{"name":"stderr","text":"Epoch [92/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.34, G_Loss=23.5] \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 92\n","output_type":"stream"},{"name":"stderr","text":"Epoch [93/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.16s/it, D_Loss=1.26, G_Loss=19.8] \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 93\n","output_type":"stream"},{"name":"stderr","text":"Epoch [94/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.16s/it, D_Loss=0.823, G_Loss=18.1]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 94 vá»›i PSNR = 22.3363, LPIPS = 0.2102, SSIM = 0.8931, FID = 178.8262, Score = 24.7001\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 94\n","output_type":"stream"},{"name":"stderr","text":"Epoch [95/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.589, G_Loss=23.6]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t táº¡i epoch 95 vá»›i PSNR = 22.3868, LPIPS = 0.2110, SSIM = 0.8939, FID = 165.5305, Score = 24.7461\nâœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 95\n","output_type":"stream"},{"name":"stderr","text":"Epoch [96/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.968, G_Loss=19.3]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 96\n","output_type":"stream"},{"name":"stderr","text":"Epoch [97/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:08<00:00,  2.16s/it, D_Loss=0.396, G_Loss=20.5]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 97\n","output_type":"stream"},{"name":"stderr","text":"Epoch [98/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.16s/it, D_Loss=0.382, G_Loss=19.2]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 98\n","output_type":"stream"},{"name":"stderr","text":"Epoch [99/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:07<00:00,  2.15s/it, D_Loss=0.235, G_Loss=21.6]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 99\n","output_type":"stream"},{"name":"stderr","text":"Epoch [100/48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [04:06<00:00,  2.14s/it, D_Loss=0.38, G_Loss=25]   \n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Warning: batch size is bigger than the data size. Setting batch size to data size\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ… ÄÃ£ lÆ°u checkpoint táº¡i epoch 100\nğŸ—œï¸ Äang nÃ©n output táº¡i epoch 100...\nğŸ—œï¸ Äang nÃ©n checkpoint táº¡i epoch 100...\n","output_type":"stream"}],"execution_count":12},{"id":"JbzCk5bolQht","cell_type":"code","source":"import zipfile\nimport torch.nn.functional as F\ndef evaluate_model(model, dataloader, real_dir, gen_dir):\n    os.makedirs(real_dir, exist_ok=True)\n    os.makedirs(gen_dir, exist_ok=True)\n\n    lpips_fn = lpips.LPIPS(net='alex').to(device)\n    to_pil = transforms.ToPILImage()\n\n    def denormalize(tensor):\n        return tensor * 0.5 + 0.5\n\n    psnr_list, ssim_list, lpips_list = [], [], []\n\n    model.eval()\n    with torch.no_grad():\n        for i, (L_channel, ab_channel) in enumerate(tqdm(dataloader)):\n            L_channel, ab_channel = L_channel.to(device), ab_channel.to(device)\n            fake_ab = model(L_channel)  # Äáº£m báº£o L_channel lÃ  1 kÃªnh\n\n            for j in range(L_channel.size(0)):\n                real_rgb = lab_to_rgb_tensor(L_channel[j:j+1], ab_channel[j:j+1]).squeeze(0)\n                fake_rgb = lab_to_rgb_tensor(L_channel[j:j+1], fake_ab[j:j+1]).squeeze(0)\n\n                real_np = denormalize(real_rgb).cpu().permute(1, 2, 0).numpy()\n                fake_np = denormalize(fake_rgb).cpu().permute(1, 2, 0).numpy()\n\n                psnr_list.append(psnr_fn(real_np, fake_np, data_range=1))\n                ssim_list.append(ssim_fn(real_np, fake_np, data_range=1, channel_axis=-1))\n                lpips_val = lpips_fn(real_rgb.unsqueeze(0).to(device), fake_rgb.unsqueeze(0).to(device)).item()\n                lpips_list.append(lpips_val)\n\n                to_pil(denormalize(real_rgb)).save(f\"{real_dir}/real_{i}_{j}.png\")\n                to_pil(denormalize(fake_rgb)).save(f\"{gen_dir}/gen_{i}_{j}.png\")\n\n    fid = fid_score.calculate_fid_given_paths([real_dir, gen_dir], batch_size=50, device=device, dims=2048)\n\n    psnr_mean = np.mean(psnr_list)\n    ssim_mean = np.mean(ssim_list)\n    lpips_mean = np.mean(lpips_list)\n\n    metrics_path = \"/kaggle/working/metrics_result.txt\"\n    with open(metrics_path, \"w\") as f:\n        f.write(f\"PSNR: {psnr_mean:.4f}\\n\")\n        f.write(f\"SSIM: {ssim_mean:.4f}\\n\")\n        f.write(f\"LPIPS: {lpips_mean:.4f}\\n\")\n        f.write(f\"FID: {fid:.4f}\\n\")\n\n    with zipfile.ZipFile(\"/kaggle/working/metrics_result.zip\", \"w\") as zipf:\n        zipf.write(metrics_path, arcname=\"metrics_result.txt\")\n\n    for dir_path, zip_path in [(real_dir, \"/kaggle/working/real_images2.zip\"), (gen_dir, \"/kaggle/working/generated_images2.zip\")]:\n        with zipfile.ZipFile(zip_path, \"w\") as zipf:\n            for root, _, files in os.walk(dir_path):\n                for file in files:\n                    full_path = os.path.join(root, file)\n                    arcname = os.path.relpath(full_path, dir_path)\n                    zipf.write(full_path, arcname=arcname)\n\n    return {\n        \"PSNR\": psnr_mean,\n        \"SSIM\": ssim_mean,\n        \"LPIPS\": lpips_mean,\n        \"FID\": fid,\n        \"psnr_list\": psnr_list,\n        \"ssim_list\": ssim_list,\n        \"lpips_list\": lpips_list\n    }\nreal_dir = '/kaggle/working/real_images2'\ngen_dir = '/kaggle/working/generated_images2'\ngenerator = UNetGenerator().to(device)\ngenerator.load_state_dict(torch.load(os.path.join(save_dir, 'generator_best.pth')))\n#generator.load_state_dict(torch.load(\"/kaggle/input/genarator_bestv2/pytorch/default/1/generator_best.pth\"))  # load láº¡i mÃ´ hÃ¬nh tá»‘t nháº¥t tá»«\n#local Ä‘á»ƒ tÃ­nh giÃ¡ trá»‹\n\ngenerator.eval()\nmetrics = evaluate_model(generator, test_loader, real_dir, gen_dir)\nprint(metrics)","metadata":{"id":"JbzCk5bolQht","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T13:50:09.611613Z","iopub.execute_input":"2025-08-11T13:50:09.611967Z","iopub.status.idle":"2025-08-11T13:51:22.253828Z","shell.execute_reply.started":"2025-08-11T13:50:09.611938Z","shell.execute_reply":"2025-08-11T13:51:22.252910Z"}},"outputs":[{"name":"stdout","text":"Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\nLoading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:58<00:00,  2.03s/it]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  3.80it/s]\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  3.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"{'PSNR': 21.08641275354926, 'SSIM': 0.88055086, 'LPIPS': 0.23457356521247, 'FID': 78.94952966935972, 'psnr_list': [20.13381149373286, 19.71510197245642, 24.20267721856691, 21.600782037907102, 16.47741405993144, 17.4081097702538, 26.50317090684908, 22.501839684947143, 24.008022063116982, 22.0026635873589, 27.78388645665774, 20.494851996560136, 18.23755843845555, 22.3554058476835, 21.245644774708264, 25.298298193071503, 14.174237046393143, 17.650933166808592, 20.818670709181482, 26.367184127161572, 24.22363766105263, 18.106956949601024, 24.70736442460654, 20.50474596653696, 24.07826857091861, 22.256121412854103, 23.493402110122435, 18.35375920062553, 17.999532060697536, 25.316722872990894, 20.363848445589184, 25.542234906119823, 22.247497123424395, 20.142973310068957, 25.29665993714136, 28.622840746882595, 23.56769647391676, 25.279033471341425, 24.18230969499705, 15.558484543458974, 24.863526090031467, 23.804763573341155, 23.52118832510017, 15.467398043358996, 26.065748221913125, 27.287308217644437, 26.044329437883782, 21.266762158112904, 24.191488735157588, 18.867631153697133, 23.488593416382606, 21.867996170555312, 25.058518252501294, 28.078622237305826, 25.500982241379177, 24.033448091343796, 18.800803913631423, 20.124565085223608, 28.03100538350153, 18.448426292624692, 24.196052039915763, 16.98448080687085, 21.377798600267035, 20.842709328407906, 21.576932498445615, 27.564883603832968, 24.16151657316249, 21.386959955667436, 17.975562505674976, 26.807265572436254, 21.08093763859756, 16.618365870907763, 24.686847120063568, 13.75460253441371, 23.78513860614465, 20.872110304924494, 22.280492710585513, 16.68356338917715, 23.496216778251085, 23.219443335640246, 18.947467307760547, 19.21631074291746, 19.125623190414164, 24.962682833165026, 22.712548654845804, 25.906250438032927, 14.773068647075975, 13.789009428478064, 21.17541095666146, 26.92754524837289, 21.19606502171008, 18.30242055080514, 21.979970048543912, 18.994490094159683, 20.58935532514711, 19.498280548630667, 13.98009487858417, 20.4727386822368, 26.13703494808351, 27.491298685986564, 22.576212304062327, 25.322710549794554, 19.94013744579783, 18.855968872464683, 14.853779362128614, 25.290027921957797, 16.67244343111387, 12.944275483800379, 19.445624938368585, 23.022367999136037, 18.36552110452044, 26.748526082503126, 24.842753366271282, 19.59061984016017, 19.39485478988258, 28.21874190918564, 25.91900248375048, 17.31655156385962, 19.289365892870897, 26.19835290403995, 22.415595091291966, 22.028303017626463, 21.754717042193548, 21.21632816205245, 21.146478321734744, 19.24819105364731, 15.55206597556131, 17.797053254893505, 22.924906568434853, 21.46157272637993, 19.89375569167965, 24.5068452833501, 19.87508519033772, 18.956890900640516, 27.541246200503544, 19.390109717009715, 16.630644932512052, 23.718311821965944, 19.969739750178572, 20.531713643357893, 21.40194564445681, 18.796505255621014, 23.73016904545962, 21.850441166657696, 24.290166802023347, 18.06209253167679, 12.491680209679533, 25.124490918830595, 20.229799289612668, 23.414636331785516, 16.60110512136378, 22.87822039894136, 25.662302271967157, 16.795062159112053, 22.368539904211985, 22.091419907135425, 17.193349142733734, 14.648654720102138, 24.51306867358706, 23.40534220738388, 19.271123853126685, 21.125122957784303, 11.788740953664313, 19.746426078049407, 21.21761573820834, 23.66751648590582, 14.879217207689235, 17.346825098096964, 18.904996332970693, 21.62133788931545, 20.741613933045578, 26.46629658640706, 15.10270844312187, 20.353674019497888, 20.566177190934873, 18.34216662502984, 17.862494991519647, 20.182058404100193, 25.642912117386345, 19.226860603896554, 22.004121021924657, 24.53487338264417, 24.451840420613635, 28.67987821563483, 9.439562487075316, 25.44611539885691, 22.016815061374135, 21.405723572363478, 23.873845949039488, 16.118992260590417, 18.28687740390429, 15.226747565908115, 23.705966428441563, 23.64382011252001, 22.436044228276746, 26.33358982054616, 20.503954408486923, 21.881132212120647, 14.939083827553166, 18.86134235963166, 22.94151460640631, 12.085325507759176, 10.717915400700274, 26.323160851445486, 24.82568856871807, 15.912902545708953, 17.649477828118595, 21.722058801865952, 17.332293734981977, 18.28812142978316, 14.139822887475258, 27.183146754254956, 26.994871022365455, 20.184309171719555, 21.88746156413891, 25.066417219055467, 19.938490720186113, 22.67260363709278, 20.7430136748018, 16.01477641439426, 24.31816133316218, 20.30241144997747, 23.969668211311564, 17.407878653642886, 25.05592644266569, 20.926193141738842, 23.228318451775955, 26.18652819808913, 29.216047253751846, 17.772269097172966, 24.737896755786185, 17.57221260733743, 20.798925761784282, 24.5320234613666, 16.487783822123458, 21.345079714271556, 23.793814587378158, 17.684119188297988, 27.074094961174456, 22.46077393427301, 20.91760677974932, 12.84464017583491, 15.921442649403978, 21.85897652316756, 17.02092231785221, 13.973859146446943, 20.82263504393325, 14.23918147261632, 23.415973943726208, 22.01772564208031, 27.237315188077517, 26.366014528288005, 26.180359203688425, 24.675152872803437, 22.266454193550093, 21.391317528868203, 20.686522716087623, 22.167323333660924, 17.799132162143852, 15.563229257709557, 25.093755583996753, 18.6314541519807, 17.901399107361186, 23.520709868995944, 16.123642707415318, 22.449086262785187, 26.06686819192307, 20.530300571135616, 15.126897588375714, 22.257524780528783, 30.660359273559745, 28.50083843041911, 17.558105403217223, 20.858647226637803, 20.503201382653383, 16.621913828955815, 20.439409543186635, 22.174437288100577, 17.804793230124403, 27.66114854108298, 24.899636797637502, 16.214357150895665, 28.02469216346026, 19.898416624666297, 17.207421784594878, 17.163330336822874, 20.76477214151714, 14.69996248902985, 13.816166742482572, 23.757731551318884, 14.208930669356864, 29.10360785725832, 23.518617322155357, 24.790056974324614, 27.825175232747835, 24.524844271439896, 27.241653569694257, 21.35514448099933, 25.85652721759334, 26.2118574493752, 20.21814856875709, 21.78003524539607, 19.933955055298057, 22.11914560490147, 17.703408286632353, 23.094279315763714, 18.191171498744296, 15.92568627756946, 19.445300511689027, 26.50004798050651, 25.05821719621274, 10.52303781497698, 23.07511171790805, 21.266492209619848, 21.129082055157706, 24.867366410863, 13.15603427508215, 24.554702546345165, 17.554383429963597, 21.149087477614476, 21.22276950689826, 15.046781461483182, 20.459676673929646, 21.76658911526404, 27.760015207799796, 22.8855336351559, 22.193298594223393, 17.215615360315756, 18.821720536296557, 18.67388425493585, 14.910248048144044, 21.200480802745695, 17.988743755248343, 18.013549191473643, 16.651410891390498, 19.892986732367753, 20.17639403801399, 24.395109659320383, 25.434158245275942, 17.164163487780666, 22.352684446267297, 18.717828389589176, 26.136236614911958, 19.81727516342471, 25.900008908423096, 22.806859653138673, 18.84776283339344, 16.42381906315568, 17.910736025376615, 26.902560228512662, 17.058118733207447, 20.92791466784337, 16.355165836546703, 25.256560255852026, 6.920092978854378, 20.545828058631074, 19.239725401386917, 25.028920463315956, 21.451802292355694, 26.28906856979608, 26.396285608582666, 21.46557869967139, 17.2188969200703, 25.600500445583833, 25.19193452154048, 19.186086875168243, 14.619354449815017, 21.122755071110557, 18.33809993571744, 24.884390237791894, 18.61352179997312, 19.602963535770282, 22.789561092629548, 27.180223735759125, 22.561004264833745, 11.886610820253383, 27.205029362742724, 14.386631708508213, 23.984304090272744, 25.11023536067523, 15.547273339450696, 27.40041985914507, 20.915183097368846, 10.481664478163, 23.980887532847667, 21.18408183350017, 20.90513725353975, 13.603672154731814, 21.911573071481627, 23.879113146691747, 23.898151633163735, 23.470927893351984, 24.924773045689772, 21.20681649236363, 19.425510176963982, 20.25278073712321, 19.29245908822965, 18.570194981762015, 26.734772553618107, 21.974502827753216, 15.2606366111703, 21.292509590332685, 21.77282618307318, 15.596472691538573, 22.06227558395811, 17.28051736716106, 23.456595237762695, 21.265705711372593, 21.443832123918895, 17.28497934882057, 17.03810272576205, 31.23140393880936, 15.557950833970931, 21.435292585505632, 23.143919015705233, 20.85101358437788, 19.736576086880785, 20.83625760370274, 18.314223075242325, 20.932267693739064, 29.765719357973826, 14.518220919086778, 18.781551483478925, 19.37840209810523, 23.668728304431454, 18.301088654766456, 23.870195932916324, 19.681850327533162, 19.501219070031514, 21.667419179780374, 15.40257486644704, 16.605240101415617, 17.79753461563447, 22.012163205405393, 22.31738781182731, 18.250184241458665, 22.351374393473208, 21.080250698598867, 18.615310937730637, 10.497384922626502, 20.339779183289505, 18.027624236429112, 19.7936369368036, 26.96398417169779, 17.30222166379133, 26.026024062474757, 22.661134995301516, 19.143171896883047, 27.14673995378748, 22.174111923980846, 14.672815604944777, 19.241277142697296, 22.034448444249634, 25.99812022140517, 25.624435749454733, 24.34391230437384, 22.360389507009547, 17.43257144645261, 26.252960465492045], 'ssim_list': [0.8552306, 0.87104076, 0.92745286, 0.92408437, 0.8453277, 0.72380114, 0.96033716, 0.93633157, 0.9071818, 0.93598145, 0.9393944, 0.8693111, 0.9077975, 0.9295545, 0.9126608, 0.92980385, 0.73311216, 0.8493135, 0.9107218, 0.96889776, 0.90041226, 0.8113759, 0.94993836, 0.79363275, 0.9417618, 0.9372228, 0.9242186, 0.8771587, 0.87376976, 0.96151763, 0.9036791, 0.96846724, 0.94288415, 0.86889696, 0.95564526, 0.9642493, 0.93659276, 0.9416204, 0.93977195, 0.7264785, 0.9589593, 0.9445967, 0.9207246, 0.80936027, 0.9630855, 0.96294993, 0.9486229, 0.8673861, 0.9284456, 0.796068, 0.9308193, 0.8898406, 0.9340689, 0.9447554, 0.9683075, 0.9527845, 0.9148006, 0.8641352, 0.95442677, 0.90707225, 0.9356806, 0.8481367, 0.91535544, 0.8653535, 0.9030723, 0.95787144, 0.94775796, 0.918071, 0.8461116, 0.95399684, 0.8755594, 0.8771222, 0.94768333, 0.6278022, 0.9376633, 0.9231224, 0.7916482, 0.70125073, 0.91145486, 0.92077726, 0.8997071, 0.8399609, 0.65681803, 0.9459088, 0.9077506, 0.952044, 0.73671937, 0.57416064, 0.9252048, 0.9571491, 0.94705933, 0.83649135, 0.90420365, 0.90396214, 0.9313751, 0.8758053, 0.80033416, 0.9183267, 0.9377528, 0.95552963, 0.925468, 0.95485944, 0.8763897, 0.87178415, 0.7610199, 0.94509697, 0.70712924, 0.6757366, 0.93458706, 0.9172979, 0.84350973, 0.94952327, 0.9614119, 0.88890666, 0.8850908, 0.97103095, 0.94977283, 0.8428685, 0.8725943, 0.9289162, 0.9473653, 0.89292, 0.9110438, 0.9117288, 0.88386613, 0.8766435, 0.83814293, 0.8178303, 0.9440246, 0.8995979, 0.8702443, 0.94762594, 0.8449793, 0.8577814, 0.9469281, 0.8413207, 0.9100701, 0.9083292, 0.8426399, 0.8667893, 0.90828174, 0.86422306, 0.9540244, 0.9173829, 0.95123297, 0.83196044, 0.5544694, 0.9536819, 0.9282982, 0.9404337, 0.6787052, 0.94059134, 0.96482176, 0.8408907, 0.8756053, 0.926624, 0.8278668, 0.6875619, 0.91646606, 0.9302718, 0.8751357, 0.8889108, 0.6553834, 0.8715744, 0.9215439, 0.9372894, 0.7275872, 0.85961694, 0.87985873, 0.8941371, 0.89607114, 0.9614335, 0.8764291, 0.87783504, 0.8966329, 0.8553875, 0.7888909, 0.92206836, 0.95076585, 0.78445625, 0.91522306, 0.9498703, 0.95894223, 0.95337147, 0.5519888, 0.9533922, 0.8899806, 0.8820534, 0.9373753, 0.7820399, 0.86717767, 0.8940123, 0.94324845, 0.9173276, 0.9297216, 0.97203666, 0.91104275, 0.9158705, 0.69106317, 0.85815924, 0.9366355, 0.57379586, 0.7633567, 0.9578309, 0.9454617, 0.77666336, 0.88583064, 0.9106546, 0.8390297, 0.869149, 0.68610173, 0.95609355, 0.97056085, 0.87960243, 0.90918463, 0.9421771, 0.87523896, 0.9440376, 0.9232889, 0.83628374, 0.9404757, 0.8840683, 0.9454133, 0.8354521, 0.94675565, 0.90957326, 0.9431575, 0.96941537, 0.9771438, 0.8707061, 0.940753, 0.7691973, 0.9075198, 0.91318494, 0.76226026, 0.92263603, 0.89177805, 0.87045866, 0.977609, 0.9187673, 0.92361647, 0.6781283, 0.7803087, 0.8837734, 0.82751423, 0.7759096, 0.9033776, 0.77267104, 0.9545634, 0.9254264, 0.9512005, 0.9569869, 0.96841025, 0.95135766, 0.95052844, 0.8563388, 0.9080715, 0.9312792, 0.8816679, 0.8194492, 0.9292455, 0.8694106, 0.8572468, 0.8962939, 0.6743973, 0.9571149, 0.9661503, 0.8959143, 0.7721556, 0.91643, 0.9512543, 0.96622705, 0.8415647, 0.85726756, 0.82294416, 0.7254445, 0.9013135, 0.9229359, 0.8594127, 0.95651793, 0.943119, 0.8336623, 0.97955394, 0.8677463, 0.8721916, 0.8183151, 0.85711557, 0.8162334, 0.7421937, 0.9472894, 0.768472, 0.97009605, 0.94348603, 0.9065097, 0.9680753, 0.9582874, 0.94526917, 0.8909981, 0.95642203, 0.94961745, 0.88756377, 0.91404414, 0.8828756, 0.9628663, 0.83283836, 0.9444442, 0.88654274, 0.7644155, 0.88594174, 0.9480593, 0.9572916, 0.6578257, 0.94940996, 0.9171998, 0.93987966, 0.943249, 0.6940113, 0.9540321, 0.82387716, 0.9163514, 0.89182526, 0.7994473, 0.9100409, 0.9244885, 0.9498964, 0.93260765, 0.9403979, 0.82662266, 0.8175096, 0.7939284, 0.75332445, 0.93357354, 0.86162025, 0.8094503, 0.7955082, 0.8497003, 0.7848423, 0.9078563, 0.9615698, 0.7540024, 0.8680989, 0.8348875, 0.96893674, 0.8569667, 0.9494249, 0.94936657, 0.87410504, 0.71719724, 0.84823895, 0.9334801, 0.82860065, 0.90613467, 0.81617475, 0.95661, 0.5345541, 0.893706, 0.86307806, 0.95668525, 0.9274843, 0.95916057, 0.96855736, 0.92526215, 0.7695864, 0.84426206, 0.931737, 0.85824275, 0.67827106, 0.8416772, 0.88026667, 0.9503619, 0.8024413, 0.91328436, 0.9481812, 0.9703488, 0.93954927, 0.77767867, 0.95681745, 0.6341243, 0.9457242, 0.896437, 0.76337767, 0.9612538, 0.92063826, 0.55715483, 0.9242723, 0.95098877, 0.89546347, 0.6950107, 0.87349147, 0.93596536, 0.91429186, 0.92581505, 0.90968627, 0.92172116, 0.84615034, 0.8350174, 0.8441135, 0.9021984, 0.95917565, 0.8977256, 0.75008845, 0.94501424, 0.93279904, 0.7272404, 0.9338446, 0.7805087, 0.93715554, 0.9252379, 0.8616696, 0.8124051, 0.88629884, 0.9712188, 0.81153196, 0.87462, 0.93676203, 0.84922355, 0.9095621, 0.90843105, 0.7893527, 0.9046566, 0.9806881, 0.61753225, 0.8445158, 0.8615823, 0.9370892, 0.78865117, 0.8871763, 0.88812894, 0.88941556, 0.88638467, 0.70780057, 0.7646149, 0.86469334, 0.8492346, 0.94208306, 0.8759692, 0.9202654, 0.90846854, 0.88367367, 0.67762566, 0.9000694, 0.8029023, 0.8659675, 0.9626294, 0.82596564, 0.92967004, 0.91600376, 0.82641673, 0.9487007, 0.9348108, 0.6471192, 0.9023759, 0.9172461, 0.9510226, 0.92471725, 0.93326765, 0.8917341, 0.85384816, 0.95246774], 'lpips_list': [0.20614029467105865, 0.2238914966583252, 0.184376060962677, 0.1901049166917801, 0.24472403526306152, 0.3299667239189148, 0.10889819264411926, 0.1925181895494461, 0.21645480394363403, 0.24679291248321533, 0.15301696956157684, 0.2386097013950348, 0.19664572179317474, 0.1796342432498932, 0.1905500590801239, 0.1621427685022354, 0.37762439250946045, 0.3644014298915863, 0.22581811249256134, 0.12879207730293274, 0.15037080645561218, 0.34451571106910706, 0.20907843112945557, 0.21016176044940948, 0.20745104551315308, 0.16820964217185974, 0.12141022086143494, 0.27275460958480835, 0.3259684443473816, 0.14663872122764587, 0.2537408471107483, 0.13005709648132324, 0.1703961342573166, 0.2530980110168457, 0.1282120943069458, 0.10979686677455902, 0.1682402491569519, 0.15616318583488464, 0.170872762799263, 0.3787037134170532, 0.15845298767089844, 0.16963624954223633, 0.15197370946407318, 0.31109678745269775, 0.10055624693632126, 0.09591560065746307, 0.14334917068481445, 0.24260637164115906, 0.2221904695034027, 0.25625717639923096, 0.15488746762275696, 0.25998803973197937, 0.16250702738761902, 0.1440580189228058, 0.11982478201389313, 0.22142577171325684, 0.1871407926082611, 0.29078930616378784, 0.08763569593429565, 0.20213329792022705, 0.13099528849124908, 0.20888471603393555, 0.2011997550725937, 0.28628551959991455, 0.23013290762901306, 0.1285516321659088, 0.2066182792186737, 0.19968640804290771, 0.35054901242256165, 0.16370265185832977, 0.14128617942333221, 0.29703325033187866, 0.13897660374641418, 0.45435112714767456, 0.16268563270568848, 0.2448674738407135, 0.13867804408073425, 0.4796195328235626, 0.18581853806972504, 0.23790714144706726, 0.26674404740333557, 0.268536239862442, 0.26708224415779114, 0.1685512661933899, 0.23014499247074127, 0.09769123792648315, 0.3126661479473114, 0.4930058717727661, 0.33531054854393005, 0.16297435760498047, 0.17449945211410522, 0.26185524463653564, 0.23974736034870148, 0.2829267382621765, 0.25763842463493347, 0.24949854612350464, 0.38114845752716064, 0.2603297531604767, 0.13164791464805603, 0.18598510324954987, 0.1634640246629715, 0.1608409434556961, 0.2500342130661011, 0.3156983554363251, 0.36350029706954956, 0.18297551572322845, 0.3237453103065491, 0.3367399275302887, 0.23097366094589233, 0.24225196242332458, 0.3373074531555176, 0.13884888589382172, 0.11976298689842224, 0.14372149109840393, 0.2809162735939026, 0.10521964728832245, 0.17945604026317596, 0.28144222497940063, 0.24985289573669434, 0.08902488648891449, 0.2039211243391037, 0.2607707679271698, 0.24720919132232666, 0.23368370532989502, 0.23677602410316467, 0.24023205041885376, 0.3453011214733124, 0.2502955496311188, 0.15232184529304504, 0.28870972990989685, 0.23456980288028717, 0.15751487016677856, 0.27532413601875305, 0.17722296714782715, 0.14567360281944275, 0.1537608802318573, 0.22426000237464905, 0.15623754262924194, 0.26264429092407227, 0.2518274486064911, 0.2556309401988983, 0.25141993165016174, 0.14614689350128174, 0.2273350954055786, 0.27461427450180054, 0.25297969579696655, 0.42361950874328613, 0.17053091526031494, 0.21212653815746307, 0.14349964261054993, 0.49245306849479675, 0.19830892980098724, 0.16085122525691986, 0.2198353409767151, 0.2066687047481537, 0.22701284289360046, 0.26909130811691284, 0.37831035256385803, 0.17425885796546936, 0.17403101921081543, 0.20733705163002014, 0.25898289680480957, 0.461012601852417, 0.2718544006347656, 0.2554163336753845, 0.1484520137310028, 0.3651331067085266, 0.2317882478237152, 0.12239725887775421, 0.2204485535621643, 0.25060921907424927, 0.10811693221330643, 0.3265995979309082, 0.3452581465244293, 0.21195444464683533, 0.3370591998100281, 0.45870062708854675, 0.24057069420814514, 0.16843372583389282, 0.2551991939544678, 0.19235633313655853, 0.13552406430244446, 0.14052599668502808, 0.20273548364639282, 0.6255577206611633, 0.1492563933134079, 0.30030500888824463, 0.23369276523590088, 0.19066831469535828, 0.3790501356124878, 0.2642362415790558, 0.23039498925209045, 0.14510615170001984, 0.19913193583488464, 0.24461710453033447, 0.184424489736557, 0.24470731616020203, 0.22763888537883759, 0.4469946324825287, 0.30288633704185486, 0.14470899105072021, 0.38202887773513794, 0.4412917494773865, 0.1802791804075241, 0.21609437465667725, 0.21911117434501648, 0.329520046710968, 0.16824722290039062, 0.34637773036956787, 0.24794548749923706, 0.3110489845275879, 0.13122926652431488, 0.12579330801963806, 0.3403882384300232, 0.18792742490768433, 0.12455467879772186, 0.23669499158859253, 0.1440339833498001, 0.2432055026292801, 0.3125889301300049, 0.15771114826202393, 0.3502230644226074, 0.17087465524673462, 0.3232722282409668, 0.1865541785955429, 0.23525765538215637, 0.10883845388889313, 0.1459067314863205, 0.15436245501041412, 0.2787937819957733, 0.20315617322921753, 0.36536869406700134, 0.23306182026863098, 0.2584533095359802, 0.5101541876792908, 0.19780416786670685, 0.23298603296279907, 0.22965359687805176, 0.14390456676483154, 0.19811584055423737, 0.2607356607913971, 0.43290022015571594, 0.4261797070503235, 0.14078721404075623, 0.3283426761627197, 0.3565577268600464, 0.26472699642181396, 0.3546335995197296, 0.11313861608505249, 0.21724244952201843, 0.10440702736377716, 0.13351809978485107, 0.1731664538383484, 0.1623060256242752, 0.29079604148864746, 0.24373605847358704, 0.22790580987930298, 0.25821763277053833, 0.21686743199825287, 0.27742254734039307, 0.10978188365697861, 0.34031355381011963, 0.3405379056930542, 0.20781347155570984, 0.4448885917663574, 0.14710518717765808, 0.19764867424964905, 0.1987549066543579, 0.3709163963794708, 0.18251660466194153, 0.12251324206590652, 0.07560215890407562, 0.29503658413887024, 0.3604976236820221, 0.3746851682662964, 0.2779941260814667, 0.31769558787345886, 0.13289271295070648, 0.18133126199245453, 0.1594635546207428, 0.14326156675815582, 0.3328877091407776, 0.07664700597524643, 0.2242787778377533, 0.4055004119873047, 0.3264443874359131, 0.21316491067409515, 0.28393539786338806, 0.42093178629875183, 0.18919318914413452, 0.2840326130390167, 0.09133735299110413, 0.14809127151966095, 0.21201199293136597, 0.13910749554634094, 0.09391329437494278, 0.166122168302536, 0.2126312255859375, 0.15927338600158691, 0.1265137791633606, 0.19479382038116455, 0.22860074043273926, 0.25161027908325195, 0.14580988883972168, 0.21242107450962067, 0.19223052263259888, 0.20625734329223633, 0.3784428536891937, 0.17986628413200378, 0.13552549481391907, 0.14064879715442657, 0.516270101070404, 0.15894167125225067, 0.24036464095115662, 0.259341835975647, 0.14719337224960327, 0.46813663840293884, 0.1685965210199356, 0.29484695196151733, 0.15466997027397156, 0.22588372230529785, 0.30314990878105164, 0.2327955812215805, 0.2097465991973877, 0.1171988695859909, 0.1926998496055603, 0.19717705249786377, 0.31288284063339233, 0.3501442074775696, 0.3477059602737427, 0.3493131101131439, 0.2085500955581665, 0.22901278734207153, 0.2310558706521988, 0.2326842099428177, 0.3527565002441406, 0.24002528190612793, 0.13297900557518005, 0.12407459318637848, 0.45606285333633423, 0.21262599527835846, 0.3098497986793518, 0.133448988199234, 0.2428392767906189, 0.16230720281600952, 0.18505796790122986, 0.20289191603660583, 0.33576318621635437, 0.2853829264640808, 0.1915903240442276, 0.2920643389225006, 0.20591357350349426, 0.33420875668525696, 0.16164857149124146, 0.5599311590194702, 0.21327020227909088, 0.23096181452274323, 0.13053342700004578, 0.217451274394989, 0.1738319844007492, 0.1673891395330429, 0.195607990026474, 0.395205020904541, 0.1862480789422989, 0.11744575947523117, 0.29408007860183716, 0.43235528469085693, 0.21447519958019257, 0.28441834449768066, 0.15424267947673798, 0.30589473247528076, 0.20882673561573029, 0.26687517762184143, 0.12905028462409973, 0.16945281624794006, 0.36157500743865967, 0.11360926926136017, 0.34143149852752686, 0.13339045643806458, 0.16655775904655457, 0.34774747490882874, 0.16529762744903564, 0.22737550735473633, 0.36206477880477905, 0.23541922867298126, 0.15630963444709778, 0.21166323125362396, 0.45231449604034424, 0.25176090002059937, 0.166814923286438, 0.1877424418926239, 0.18876402080059052, 0.1948852241039276, 0.19094428420066833, 0.2701417803764343, 0.24567925930023193, 0.22333958745002747, 0.21267829835414886, 0.13475961983203888, 0.2666785418987274, 0.32529640197753906, 0.2569297254085541, 0.20013193786144257, 0.371541291475296, 0.18726162612438202, 0.25292280316352844, 0.1542620211839676, 0.19069218635559082, 0.16999730467796326, 0.37768980860710144, 0.3035318851470947, 0.080480195581913, 0.3322494328022003, 0.3112286329269409, 0.20758895576000214, 0.22624780237674713, 0.21669363975524902, 0.25332245230674744, 0.2869430184364319, 0.2242659479379654, 0.07428674399852753, 0.3482438027858734, 0.2434690296649933, 0.24868100881576538, 0.12291277945041656, 0.4276256263256073, 0.14483878016471863, 0.24433952569961548, 0.24773181974887848, 0.27751097083091736, 0.4888421595096588, 0.36215925216674805, 0.35129112005233765, 0.2420666217803955, 0.12790332734584808, 0.2477940320968628, 0.18978843092918396, 0.17412422597408295, 0.235737144947052, 0.4014415442943573, 0.2403860092163086, 0.30281129479408264, 0.23230989277362823, 0.13989698886871338, 0.3316323161125183, 0.11582736670970917, 0.1611650139093399, 0.28738152980804443, 0.14844894409179688, 0.20658692717552185, 0.37479835748672485, 0.20578980445861816, 0.22023604810237885, 0.18504154682159424, 0.12130345404148102, 0.2621227502822876, 0.21680521965026855, 0.3508654832839966, 0.14178475737571716]}\n","output_type":"stream"}],"execution_count":13},{"id":"ba7ce973-6d23-4e5a-b997-ce934ced02e3","cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Äá»c file metrics_result.txt tá»« input\nfile_path = \"/kaggle/input/training/pytorch/default/1/trainning_chy.txt\"\n\ndf = pd.read_csv(file_path)\n\n# TrÃ­ch xuáº¥t cÃ¡c cá»™t\nepochs = df['Epoch']\nG_losses = df['G_loss']\nD_losses = df['D_loss']\nPSNR = df['PSNR']\nSSIM = df['SSIM']\nLPIPS = df['LPIPS']\n\n# Váº½ biá»ƒu Ä‘á»“\nplt.figure(figsize=(14, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(epochs, G_losses, label='G Loss')\nplt.plot(epochs, D_losses, label='D Loss')\nplt.title('Loss qua cÃ¡c Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs, PSNR, color='green')\nplt.title('PSNR theo Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('PSNR')\n\nplt.subplot(2, 2, 3)\nplt.plot(epochs, SSIM, color='blue')\nplt.title('SSIM theo Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('SSIM')\n\nplt.subplot(2, 2, 4)\nplt.plot(epochs, LPIPS, color='red')\nplt.title('LPIPS theo Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('LPIPS')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7fd82cd3-335c-42ab-ac65-07af7c4ff0bd","cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.plot(range(start_epoch , start_epoch + 1 + len(G_losses)), G_losses, label=\"G Loss\", color='blue')\nplt.plot(range(start_epoch , start_epoch + 1 + len(D_losses)), D_losses, label=\"D Loss\", color='red')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"G and D Loss over Epochs\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(save_dir, \"loss_over_epochs.png\"))\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b598d5fe-6e3f-4a93-b6dd-398deec81cc1","cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.plot(range(start_epoch + 1, start_epoch + 1 + len(PSNR_scores)), PSNR_scores, marker='o', color='green', label=\"PSNR\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"PSNR\")\nplt.title(\"PSNR over Epochs\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(save_dir, \"psnr_over_epochs.png\"))\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2384b21d-d9fc-456d-9128-e7195dd618bd","cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.plot(range(start_epoch + 1, start_epoch + 1 + len(SSIM_scores)), SSIM_scores, marker='o', color='orange', label=\"SSIM\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"SSIM\")\nplt.title(\"SSIM over Epochs\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(save_dir, \"ssim_over_epochs.png\"))\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c5567f9b-d856-4128-8dd9-204003e6c2b7","cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.plot(range(start_epoch + 1, start_epoch + 1 + len(LPIPS_scores)), LPIPS_scores, marker='o', color='purple', label=\"LPIPS\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"LPIPS\")\nplt.title(\"LPIPS over Epochs\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(save_dir, \"lpips_over_epochs.png\"))\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"253063ca-4a4f-4b69-bbb5-7de54dc458bb","cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.plot(range(start_epoch + 1, start_epoch + 1 + len(FID_scores)), FID_scores, label='FID', color='brown')\nplt.title('FID per Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('FID')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.savefig(os.path.join(save_dir, 'fid_curve.png'))\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"958526b6-62b8-413e-8d1d-20ab8e86d993","cell_type":"code","source":"# Váº½ PSNR\nimport matplotlib.pyplot as plt\n\npsnr_list = metrics['psnr_list']\nplt.figure(figsize=(8, 5))\nplt.plot(psnr_list, marker='o', color='blue', label='PSNR')\nplt.title(\"PSNR over Test Images\")\nplt.xlabel(\"Image Index\")\nplt.ylabel(\"PSNR\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.savefig(\"/kaggle/working/psnr_over_images.png\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"95ccafa2-151f-4501-bcbf-ba1a988a9beb","cell_type":"code","source":"ssim_list = metrics['ssim_list']\nplt.figure(figsize=(8, 5))\nplt.plot(ssim_list, marker='s', color='green', label='SSIM')\nplt.title(\"SSIM over Epochs\")\nplt.xlabel(\"Image Index\")\nplt.ylabel(\"SSIM\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.savefig(\"/kaggle/working/ssim_over_epochs.png\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"77da8a86-74c5-4cab-8830-a6eb7f01c21a","cell_type":"code","source":"lpips_list = metrics['lpips_list']\nplt.figure(figsize=(8, 5))\nplt.plot( lpips_list, marker='^', color='red', label='LPIPS')\nplt.title(\"LPIPS over Epochs\")\nplt.xlabel(\"Image Index\")\nplt.ylabel(\"LPIPS\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.savefig(\"/kaggle/working/lpips_over_epochs.png\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}